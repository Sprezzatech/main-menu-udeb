Template: s390/netcfg/choose_networktype
Type: select
Choices: ${choices}
Description: Select the type of your network device.
 The following network devices are supported. Choose the type of your primary
 network interface that you will need for installing the Debian system (via NFS
 or HTTP).

Template: s390/netcfg/common/get_read
Type: select
Choices: ${choices}
Description: Read device number.
 The following devices are available.

Template: s390/netcfg/common/get_write
Type: select
Choices: ${choices}
Description: Write device number.
 Can't find write device number, please select.
  The following devices are available.

Template: s390/netcfg/common/get_data
Type: select
Choices: ${choices}
Description: Data device number.
 Can't find data device number, please select.
  The following devices are available.

Template: s390/netcfg/ctc/no
Type: note
Description: No CTC or ESCON connections were detected.
 No CTC or ESCON connections were detected. Please make sure that you have set
 them up correctly.

Template: s390/netcfg/ctc/confirm_one
Type: boolean
Default: true
Description: One CTC or ESCON connections detected. Correct?
  read channel  = ${devno_read}
  write channel = ${devno_write}

Template: s390/netcfg/ctc/confirm
Type: boolean
Default: true
Description: Is this configuration correct?
  read channel  = ${devno_read}
  write channel = ${devno_write}
  protocol      = ${protocol}

Template: s390/netcfg/ctc/protocol
Type: select
Choices: 0: s/390, 1: linux, 2: linux tty, 3: os/390
Description: Please specify protocol for this connection.
 Please specify protocol for this connection.

Template: s390/netcfg/lcs/no
Type: note
Description: No OSA-2 or OSA-Express cards were detected.
 No OSA-2 or OSA-Express cards were detected. If you are running VM please make
 sure that your card is attached to this guest. If you want to use HiperSockets
 or an OSA-Express card in QDIO mode please use the qeth driver instead.

Template: s390/netcfg/lcs/confirm_one
Type: boolean
Default: true
Description: One OSA-2 or OSA-Express card detected. Correct?
  read channel  = ${devno_read}
  write channel = ${devno_write}

Template: s390/netcfg/lcs/confirm
Type: boolean
Default: true
Description: Is this configuration correct?
  read channel  = ${devno_read}
  write channel = ${devno_write}
  port          = ${port}

Template: s390/netcfg/lcs/port
Type: select
Choices: 0: port 0, 1: port 1, 2: port 2, 3: port 3
Description: Please specify port for this connection.
 Please specify relative port.

Template: s390/netcfg/qeth/no
Type: note
Description: No OSA-Express QDIO cards / HiperSockets were detected.
 No OSA-Express QDIO cards / HiperSockets were detected. If you are running VM
 please make sure that your card is attached to this guest. If you want to use
 an OSA-2 or OSA-Express card in non-QDIO mode please use the lcs driver
 instead.

Template: s390/netcfg/qeth/confirm_one
Type: boolean
Default: true
Description: One OSA-2 or OSA-Express card detected. Correct?
  read channel  = ${devno_read}
  write channel = ${devno_write}
  data channel  = ${devno_data}

Template: s390/netcfg/qeth/confirm
Type: boolean
Default: true
Description: Is this configuration correct?
  read channel  = ${devno_read}
  write channel = ${devno_write}
  data channel  = ${devno_data}
  port          = ${port}

Template: s390/netcfg/qeth/port
Type: select
Choices: 0: port 0, 1: port 1
Description: Please specify port.
 Please specify relative port.

Template: s390/netcfg/qeth/postname
Type: string
Description: Please specify postname.
 Please enter the portname of your OSA-Express card. This name must be 1 to 8
 characters long and must be equal on all systems accessing the same card!
 Leave it empty if you want to use HiperSockets. This parameter is required
 for cards with microcode level 2.10 or later or when you want to share a
 card. The name will be converted to uppercase letters automatically!

Template: s390/netcfg/iucv/peer
Type: string
Description: Please specify the VM peer.
 Please enter the name of the VM peer you want to connect to. If you want to
 connect to multiple peers, separate the names by colons, e.g. tcpip:linux1
 The standard TCP/IP server name on VM is TCPIP, on VIF it's $TCPIP.
 Note: IUCV must be enabled in the VM user directory for this driver to work and
 it must be set up on both ends of the communication.

